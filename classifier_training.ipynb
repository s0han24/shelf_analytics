{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bffb4c9c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T10:05:15.576659Z",
     "iopub.status.busy": "2024-07-04T10:05:15.576375Z",
     "iopub.status.idle": "2024-07-04T10:05:22.996719Z",
     "shell.execute_reply": "2024-07-04T10:05:22.995752Z"
    },
    "papermill": {
     "duration": 7.427958,
     "end_time": "2024-07-04T10:05:22.999038",
     "exception": false,
     "start_time": "2024-07-04T10:05:15.571080",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import torch\n",
    "from torchvision import datasets, models, transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn as nn\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import time\n",
    "import copy\n",
    "from PIL import Image\n",
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52488c3c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T10:05:23.008237Z",
     "iopub.status.busy": "2024-07-04T10:05:23.007791Z",
     "iopub.status.idle": "2024-07-04T10:05:23.012012Z",
     "shell.execute_reply": "2024-07-04T10:05:23.011170Z"
    },
    "papermill": {
     "duration": 0.010855,
     "end_time": "2024-07-04T10:05:23.013924",
     "exception": false,
     "start_time": "2024-07-04T10:05:23.003069",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be7f3056",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T10:05:23.022062Z",
     "iopub.status.busy": "2024-07-04T10:05:23.021782Z",
     "iopub.status.idle": "2024-07-04T10:05:23.026889Z",
     "shell.execute_reply": "2024-07-04T10:05:23.026069Z"
    },
    "papermill": {
     "duration": 0.011265,
     "end_time": "2024-07-04T10:05:23.028745",
     "exception": false,
     "start_time": "2024-07-04T10:05:23.017480",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "transform = transforms.Compose([        # Defining a variable transforms\n",
    " transforms.Resize(256),                # Resize the image to 256×256 pixels\n",
    " transforms.CenterCrop(224),            # Crop the image to 224×224 pixels about the center\n",
    " transforms.ToTensor(),                 # Convert the image to PyTorch Tensor data type\n",
    " transforms.Normalize(                  # Normalize the image\n",
    " mean=[0.485, 0.456, 0.406],            # Mean and std of image as also used when training the network\n",
    " std=[0.229, 0.224, 0.225]      \n",
    ")])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba9ae3fc",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T10:05:23.036750Z",
     "iopub.status.busy": "2024-07-04T10:05:23.036483Z",
     "iopub.status.idle": "2024-07-04T10:05:23.155375Z",
     "shell.execute_reply": "2024-07-04T10:05:23.154199Z"
    },
    "papermill": {
     "duration": 0.126159,
     "end_time": "2024-07-04T10:05:23.158419",
     "exception": false,
     "start_time": "2024-07-04T10:05:23.032260",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_path</th>\n",
       "      <th>class_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>/kaggle/input/classify-by-brand-dataset/classi...</td>\n",
       "      <td>not himalaya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>/kaggle/input/classify-by-brand-dataset/classi...</td>\n",
       "      <td>himalaya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>/kaggle/input/classify-by-brand-dataset/classi...</td>\n",
       "      <td>not himalaya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>/kaggle/input/classify-by-brand-dataset/classi...</td>\n",
       "      <td>not himalaya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>/kaggle/input/classify-by-brand-dataset/classi...</td>\n",
       "      <td>not himalaya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11889</th>\n",
       "      <td>/kaggle/input/classify-by-brand-dataset/classi...</td>\n",
       "      <td>himalaya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11890</th>\n",
       "      <td>/kaggle/input/classify-by-brand-dataset/classi...</td>\n",
       "      <td>himalaya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11891</th>\n",
       "      <td>/kaggle/input/classify-by-brand-dataset/classi...</td>\n",
       "      <td>himalaya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11892</th>\n",
       "      <td>/kaggle/input/classify-by-brand-dataset/classi...</td>\n",
       "      <td>himalaya</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11893</th>\n",
       "      <td>/kaggle/input/classify-by-brand-dataset/classi...</td>\n",
       "      <td>himalaya</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11894 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              image_path   class_label\n",
       "0      /kaggle/input/classify-by-brand-dataset/classi...  not himalaya\n",
       "1      /kaggle/input/classify-by-brand-dataset/classi...      himalaya\n",
       "2      /kaggle/input/classify-by-brand-dataset/classi...  not himalaya\n",
       "3      /kaggle/input/classify-by-brand-dataset/classi...  not himalaya\n",
       "4      /kaggle/input/classify-by-brand-dataset/classi...  not himalaya\n",
       "...                                                  ...           ...\n",
       "11889  /kaggle/input/classify-by-brand-dataset/classi...      himalaya\n",
       "11890  /kaggle/input/classify-by-brand-dataset/classi...      himalaya\n",
       "11891  /kaggle/input/classify-by-brand-dataset/classi...      himalaya\n",
       "11892  /kaggle/input/classify-by-brand-dataset/classi...      himalaya\n",
       "11893  /kaggle/input/classify-by-brand-dataset/classi...      himalaya\n",
       "\n",
       "[11894 rows x 2 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/kaggle/input/classify-by-brand-dataset-fixed/classify_by_brand/new_image_classification.csv')\n",
    "sampler = RandomOverSampler(random_state=42)\n",
    "X = df['image_path'].values\n",
    "X = X.reshape(-1,1)\n",
    "Y = df['class_label']\n",
    "\n",
    "X_res, Y_res = sampler.fit_resample(X,Y)\n",
    "\n",
    "X_list = map(lambda x: x[0], X_res)\n",
    "df = pd.concat([pd.Series(X_list, dtype='string', name='image_path'), Y_res], axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55b40d24",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T10:05:23.171778Z",
     "iopub.status.busy": "2024-07-04T10:05:23.171294Z",
     "iopub.status.idle": "2024-07-04T10:05:23.180588Z",
     "shell.execute_reply": "2024-07-04T10:05:23.179166Z"
    },
    "papermill": {
     "duration": 0.017591,
     "end_time": "2024-07-04T10:05:23.182896",
     "exception": false,
     "start_time": "2024-07-04T10:05:23.165305",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "class Himalaya_dataset(Dataset):\n",
    "    def __init__(self, img_dir, label_dir, transform, target_transform=None):\n",
    "#         self.img_labels = pd.read_csv(label_dir)\n",
    "        self.img_labels = df\n",
    "        self.img_dir = img_dir\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.img_labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n",
    "        image = Image.open(img_path)\n",
    "        label = self.img_labels.iloc[idx, 1]\n",
    "        label = torch.Tensor([clas[label]])\n",
    "        image = self.transform(image)\n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dbb2227e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T10:05:23.195451Z",
     "iopub.status.busy": "2024-07-04T10:05:23.195092Z",
     "iopub.status.idle": "2024-07-04T10:05:23.200767Z",
     "shell.execute_reply": "2024-07-04T10:05:23.199466Z"
    },
    "papermill": {
     "duration": 0.015063,
     "end_time": "2024-07-04T10:05:23.203127",
     "exception": false,
     "start_time": "2024-07-04T10:05:23.188064",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "img_dir = \"/kaggle/input/classify-by-brand-dataset/classify_by_brand\"\n",
    "train_dataset = Himalaya_dataset(img_dir, \"/kaggle/input/classify-by-brand-dataset-fixed/classify_by_brand/new_image_classification.csv\", transform)\n",
    "cv_dataset = Himalaya_dataset(img_dir, \"/kaggle/input/brand-cv/image_classification3.csv\", transform)\n",
    "dataset_sizes = {\"train\": len(train_dataset), \"cv\": len(cv_dataset)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a0ad265e",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T10:05:23.214016Z",
     "iopub.status.busy": "2024-07-04T10:05:23.213752Z",
     "iopub.status.idle": "2024-07-04T10:05:23.219070Z",
     "shell.execute_reply": "2024-07-04T10:05:23.218167Z"
    },
    "papermill": {
     "duration": 0.013142,
     "end_time": "2024-07-04T10:05:23.221464",
     "exception": false,
     "start_time": "2024-07-04T10:05:23.208322",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "bs = 200\n",
    "train = torch.utils.data.DataLoader(train_dataset, batch_size = bs, shuffle = True)\n",
    "cv = torch.utils.data.DataLoader(cv_dataset, shuffle = True)\n",
    "dataloaders = {\"train\": train, \"cv\": cv}\n",
    "clas = {\"not himalaya\": 0., \"himalaya\": 1.}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8eb68c8d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T10:05:23.233093Z",
     "iopub.status.busy": "2024-07-04T10:05:23.232831Z",
     "iopub.status.idle": "2024-07-04T10:05:23.245485Z",
     "shell.execute_reply": "2024-07-04T10:05:23.244662Z"
    },
    "papermill": {
     "duration": 0.021106,
     "end_time": "2024-07-04T10:05:23.247738",
     "exception": false,
     "start_time": "2024-07-04T10:05:23.226632",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, num_epochs=25):\n",
    "    since = time.time()\n",
    "\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'cv']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for inputs, labels in tqdm(dataloaders[phase]):\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        optimizer.zero_grad()\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_sizes[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "\n",
    "            # deep copy the model\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = copy.deepcopy(model.state_dict())\n",
    "\n",
    "        print()\n",
    "\n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    print('Best val Acc: {:4f}'.format(best_acc))\n",
    "\n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "faec681d",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T10:05:23.262000Z",
     "iopub.status.busy": "2024-07-04T10:05:23.261704Z",
     "iopub.status.idle": "2024-07-04T10:05:24.225437Z",
     "shell.execute_reply": "2024-07-04T10:05:24.224542Z"
    },
    "papermill": {
     "duration": 0.974635,
     "end_time": "2024-07-04T10:05:24.227566",
     "exception": false,
     "start_time": "2024-07-04T10:05:23.252931",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n",
      "Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n",
      "100%|██████████| 44.7M/44.7M [00:00<00:00, 148MB/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Sequential(\n",
       "  (0): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Linear(in_features=512, out_features=1, bias=True)\n",
       "  )\n",
       "  (1): Sigmoid()\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_dir = '/kaggle/input/classify-by-brand-dataset-fixed/classify_by_brand/classify_by_brand_dataset'\n",
    "\n",
    "model = models.resnet18(pretrained = True)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "num_ftrs = model.fc.in_features\n",
    "model.fc = nn.Linear(num_ftrs, 1)\n",
    "model = nn.Sequential(model, nn.Sigmoid())\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebd6b937",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2024-07-04T10:05:24.238617Z",
     "iopub.status.busy": "2024-07-04T10:05:24.238316Z",
     "iopub.status.idle": "2024-07-04T11:03:18.330616Z",
     "shell.execute_reply": "2024-07-04T11:03:18.329580Z"
    },
    "papermill": {
     "duration": 3474.100286,
     "end_time": "2024-07-04T11:03:18.332842",
     "exception": false,
     "start_time": "2024-07-04T10:05:24.232556",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [01:59<00:00,  1.99s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.5695 Acc: 99.5544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11894/11894 [01:23<00:00, 143.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv Loss: 0.4304 Acc: 0.5000\n",
      "\n",
      "Epoch 1/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:52<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3865 Acc: 99.6257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11894/11894 [01:24<00:00, 140.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv Loss: 0.3473 Acc: 0.5000\n",
      "\n",
      "Epoch 2/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:51<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3332 Acc: 99.6257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11894/11894 [01:23<00:00, 142.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv Loss: 0.3120 Acc: 0.5000\n",
      "\n",
      "Epoch 3/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:52<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.3056 Acc: 99.5455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11894/11894 [01:23<00:00, 142.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv Loss: 0.2908 Acc: 0.5000\n",
      "\n",
      "Epoch 4/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:51<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2887 Acc: 99.6257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11894/11894 [01:23<00:00, 143.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv Loss: 0.2773 Acc: 0.5000\n",
      "\n",
      "Epoch 5/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:51<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2759 Acc: 99.6079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11894/11894 [01:23<00:00, 143.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv Loss: 0.2673 Acc: 0.5000\n",
      "\n",
      "Epoch 6/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:50<00:00,  1.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2674 Acc: 99.5811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11894/11894 [01:23<00:00, 142.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv Loss: 0.2569 Acc: 0.5000\n",
      "\n",
      "Epoch 7/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:51<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2613 Acc: 99.5187\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11894/11894 [01:24<00:00, 140.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv Loss: 0.2564 Acc: 0.5000\n",
      "\n",
      "Epoch 8/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:53<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2591 Acc: 99.5544\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11894/11894 [01:26<00:00, 137.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv Loss: 0.2553 Acc: 0.5000\n",
      "\n",
      "Epoch 9/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:53<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2586 Acc: 99.5455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11894/11894 [01:23<00:00, 141.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv Loss: 0.2549 Acc: 0.5000\n",
      "\n",
      "Epoch 10/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:52<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2566 Acc: 99.6257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11894/11894 [01:23<00:00, 142.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv Loss: 0.2544 Acc: 0.5000\n",
      "\n",
      "Epoch 11/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:51<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2567 Acc: 99.5455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11894/11894 [01:23<00:00, 142.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv Loss: 0.2531 Acc: 0.5000\n",
      "\n",
      "Epoch 12/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:51<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2568 Acc: 99.5811\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11894/11894 [01:23<00:00, 143.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv Loss: 0.2517 Acc: 0.5000\n",
      "\n",
      "Epoch 13/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:52<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2568 Acc: 99.5900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11894/11894 [01:23<00:00, 142.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv Loss: 0.2523 Acc: 0.5000\n",
      "\n",
      "Epoch 14/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:51<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2551 Acc: 99.5633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11894/11894 [01:24<00:00, 141.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv Loss: 0.2521 Acc: 0.5000\n",
      "\n",
      "Epoch 15/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:51<00:00,  1.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2551 Acc: 99.5990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11894/11894 [01:24<00:00, 141.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv Loss: 0.2517 Acc: 0.5000\n",
      "\n",
      "Epoch 16/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:52<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2545 Acc: 99.5277\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11894/11894 [01:24<00:00, 140.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv Loss: 0.2514 Acc: 0.5000\n",
      "\n",
      "Epoch 17/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:51<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2550 Acc: 99.6168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11894/11894 [01:23<00:00, 142.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv Loss: 0.2517 Acc: 0.5000\n",
      "\n",
      "Epoch 18/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:51<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2559 Acc: 99.5990\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11894/11894 [01:24<00:00, 140.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv Loss: 0.2520 Acc: 0.5000\n",
      "\n",
      "Epoch 19/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:52<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2549 Acc: 99.5722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11894/11894 [01:23<00:00, 141.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv Loss: 0.2510 Acc: 0.5000\n",
      "\n",
      "Epoch 20/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:52<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2563 Acc: 99.4831\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11894/11894 [01:24<00:00, 140.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv Loss: 0.2517 Acc: 0.5000\n",
      "\n",
      "Epoch 21/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:52<00:00,  1.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2551 Acc: 99.5455\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11894/11894 [01:25<00:00, 139.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv Loss: 0.2522 Acc: 0.5000\n",
      "\n",
      "Epoch 22/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:51<00:00,  1.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2547 Acc: 99.5900\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11894/11894 [01:24<00:00, 141.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv Loss: 0.2514 Acc: 0.5000\n",
      "\n",
      "Epoch 23/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:52<00:00,  1.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2557 Acc: 99.6346\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11894/11894 [01:25<00:00, 139.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv Loss: 0.2515 Acc: 0.5000\n",
      "\n",
      "Epoch 24/24\n",
      "----------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 60/60 [00:52<00:00,  1.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train Loss: 0.2545 Acc: 99.5722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 11894/11894 [01:25<00:00, 139.89it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cv Loss: 0.2511 Acc: 0.5000\n",
      "\n",
      "Training complete in 57m 54s\n",
      "Best val Acc: 0.000000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCELoss()\n",
    "opt = torch.optim.SGD(model[0].fc.parameters(), lr=0.001, momentum=0.9)\n",
    "exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(opt, step_size=7, gamma=0.1)\n",
    "model = train_model(model, criterion, opt,\n",
    "                         exp_lr_scheduler, num_epochs=25)"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "datasetId": 5231552,
     "sourceId": 8719033,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 5231641,
     "sourceId": 8719138,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 30733,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 3488.761167,
   "end_time": "2024-07-04T11:03:21.611623",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2024-07-04T10:05:12.850456",
   "version": "2.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
