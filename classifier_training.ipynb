{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8719033,"sourceType":"datasetVersion","datasetId":5231552},{"sourceId":8719138,"sourceType":"datasetVersion","datasetId":5231641}],"dockerImageVersionId":30733,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\nimport torch\nfrom torchvision import datasets, models, transforms\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn\nimport os\nfrom tqdm import tqdm\nimport time\nimport copy\nfrom PIL import Image\nfrom imblearn.over_sampling import RandomOverSampler","metadata":{"execution":{"iopub.status.busy":"2024-07-16T07:51:47.441765Z","iopub.execute_input":"2024-07-16T07:51:47.442650Z","iopub.status.idle":"2024-07-16T07:51:47.448578Z","shell.execute_reply.started":"2024-07-16T07:51:47.442617Z","shell.execute_reply":"2024-07-16T07:51:47.447356Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"device = torch.device('cuda')","metadata":{"execution":{"iopub.status.busy":"2024-07-16T07:51:47.450531Z","iopub.execute_input":"2024-07-16T07:51:47.450898Z","iopub.status.idle":"2024-07-16T07:51:47.460961Z","shell.execute_reply.started":"2024-07-16T07:51:47.450856Z","shell.execute_reply":"2024-07-16T07:51:47.460092Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"transform = transforms.Compose([        # Defining a variable transforms\n transforms.Resize(256),                # Resize the image to 256×256 pixels\n transforms.CenterCrop(224),            # Crop the image to 224×224 pixels about the center\n transforms.ToTensor(),                 # Convert the image to PyTorch Tensor data type\n transforms.Normalize(                  # Normalize the image\n mean=[0.485, 0.456, 0.406],            # Mean and std of image as also used when training the network\n std=[0.229, 0.224, 0.225]      \n)])","metadata":{"execution":{"iopub.status.busy":"2024-07-16T07:51:47.462472Z","iopub.execute_input":"2024-07-16T07:51:47.462770Z","iopub.status.idle":"2024-07-16T07:51:47.473232Z","shell.execute_reply.started":"2024-07-16T07:51:47.462735Z","shell.execute_reply":"2024-07-16T07:51:47.472302Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"df = pd.read_csv('/kaggle/input/classify-by-brand-dataset-fixed/classify_by_brand/new_image_classification.csv')\nsampler = RandomOverSampler(random_state=42)\nX = df['image_path'].values\nX = X.reshape(-1,1)\nY = df['class_label']\n\nX_res, Y_res = sampler.fit_resample(X,Y)\n\nX_list = map(lambda x: x[0], X_res)\ndf = pd.concat([pd.Series(X_list, dtype='string', name='image_path'), Y_res], axis=1)\ndf","metadata":{"execution":{"iopub.status.busy":"2024-07-16T07:51:47.475824Z","iopub.execute_input":"2024-07-16T07:51:47.476180Z","iopub.status.idle":"2024-07-16T07:51:47.552907Z","shell.execute_reply.started":"2024-07-16T07:51:47.476140Z","shell.execute_reply":"2024-07-16T07:51:47.551866Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"                                              image_path   class_label\n0      /kaggle/input/classify-by-brand-dataset/classi...  not himalaya\n1      /kaggle/input/classify-by-brand-dataset/classi...      himalaya\n2      /kaggle/input/classify-by-brand-dataset/classi...  not himalaya\n3      /kaggle/input/classify-by-brand-dataset/classi...  not himalaya\n4      /kaggle/input/classify-by-brand-dataset/classi...  not himalaya\n...                                                  ...           ...\n11889  /kaggle/input/classify-by-brand-dataset/classi...      himalaya\n11890  /kaggle/input/classify-by-brand-dataset/classi...      himalaya\n11891  /kaggle/input/classify-by-brand-dataset/classi...      himalaya\n11892  /kaggle/input/classify-by-brand-dataset/classi...      himalaya\n11893  /kaggle/input/classify-by-brand-dataset/classi...      himalaya\n\n[11894 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>image_path</th>\n      <th>class_label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>/kaggle/input/classify-by-brand-dataset/classi...</td>\n      <td>not himalaya</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>/kaggle/input/classify-by-brand-dataset/classi...</td>\n      <td>himalaya</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>/kaggle/input/classify-by-brand-dataset/classi...</td>\n      <td>not himalaya</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>/kaggle/input/classify-by-brand-dataset/classi...</td>\n      <td>not himalaya</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>/kaggle/input/classify-by-brand-dataset/classi...</td>\n      <td>not himalaya</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>11889</th>\n      <td>/kaggle/input/classify-by-brand-dataset/classi...</td>\n      <td>himalaya</td>\n    </tr>\n    <tr>\n      <th>11890</th>\n      <td>/kaggle/input/classify-by-brand-dataset/classi...</td>\n      <td>himalaya</td>\n    </tr>\n    <tr>\n      <th>11891</th>\n      <td>/kaggle/input/classify-by-brand-dataset/classi...</td>\n      <td>himalaya</td>\n    </tr>\n    <tr>\n      <th>11892</th>\n      <td>/kaggle/input/classify-by-brand-dataset/classi...</td>\n      <td>himalaya</td>\n    </tr>\n    <tr>\n      <th>11893</th>\n      <td>/kaggle/input/classify-by-brand-dataset/classi...</td>\n      <td>himalaya</td>\n    </tr>\n  </tbody>\n</table>\n<p>11894 rows × 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"class Himalaya_dataset(Dataset):\n    def __init__(self, img_dir, label_dir, transform, phase, target_transform=None):\n        if phase=='cv': \n            self.img_labels = pd.read_csv(label_dir)\n        else:\n            self.img_labels = df\n        self.img_dir = img_dir\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.img_labels)\n\n    def __getitem__(self, idx):\n        img_path = os.path.join(self.img_dir, self.img_labels.iloc[idx, 0])\n        image = Image.open(img_path)\n        label = self.img_labels.iloc[idx, 1]\n        label = torch.Tensor([clas[label]])\n        image = self.transform(image)\n        return image, label","metadata":{"execution":{"iopub.status.busy":"2024-07-16T07:51:47.554377Z","iopub.execute_input":"2024-07-16T07:51:47.554845Z","iopub.status.idle":"2024-07-16T07:51:47.563753Z","shell.execute_reply.started":"2024-07-16T07:51:47.554805Z","shell.execute_reply":"2024-07-16T07:51:47.562634Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"img_dir = \"/kaggle/input/classify-by-brand-dataset/classify_by_brand\"\ntrain_dataset = Himalaya_dataset(img_dir, \"/kaggle/input/classify-by-brand-dataset-fixed/classify_by_brand/new_image_classification.csv\", transform, phase='train')\ncv_dataset = Himalaya_dataset(img_dir, \"/kaggle/input/classify-by-brand-dataset/classify_by_brand/image_classification_test.csv\", transform, phase='cv')\ndataset_sizes = {\"train\": len(train_dataset), \"cv\": len(cv_dataset)}","metadata":{"execution":{"iopub.status.busy":"2024-07-16T07:51:47.565655Z","iopub.execute_input":"2024-07-16T07:51:47.566067Z","iopub.status.idle":"2024-07-16T07:51:47.610233Z","shell.execute_reply.started":"2024-07-16T07:51:47.566029Z","shell.execute_reply":"2024-07-16T07:51:47.609298Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"bs = 200\ntrain = torch.utils.data.DataLoader(train_dataset, batch_size = bs, shuffle = True)\ncv = torch.utils.data.DataLoader(cv_dataset, shuffle = True)\ndataloaders = {\"train\": train, \"cv\": cv}\nclas = {\"not himalaya\": 0., \"himalaya\": 1.}","metadata":{"execution":{"iopub.status.busy":"2024-07-16T07:51:47.611530Z","iopub.execute_input":"2024-07-16T07:51:47.611934Z","iopub.status.idle":"2024-07-16T07:51:47.618611Z","shell.execute_reply.started":"2024-07-16T07:51:47.611896Z","shell.execute_reply":"2024-07-16T07:51:47.617418Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"def train_model(model, criterion, optimizer, num_epochs=25):\n    since = time.time()\n\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n\n    for epoch in range(num_epochs):\n        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n        print('-' * 10)\n\n        # Each epoch has a training and validation phase\n        for phase in ['train', 'cv']:\n            if phase == 'train':\n                model.train()  # Set model to training mode\n            else:\n                model.eval()   # Set model to evaluate mode\n\n            running_loss = 0.0\n            running_corrects = 0\n\n            # Iterate over data.\n            for inputs, labels in tqdm(dataloaders[phase]):\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n                # forward\n                # track history if only in train\n                with torch.set_grad_enabled(phase == 'train'):\n                    outputs = model(inputs)\n                    preds = torch.round(outputs)\n                    loss = criterion(outputs, labels)\n\n                    # backward + optimize only if in training phase\n                    if phase == 'train':\n                        optimizer.zero_grad()\n                        loss.backward()\n                        optimizer.step()\n\n                # statistics\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n            if phase == 'train':\n                optimizer.step()\n\n            epoch_loss = running_loss / dataset_sizes[phase]\n            epoch_acc = running_corrects.float() / dataset_sizes[phase]\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc))\n\n            # deep copy the model\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n        print()\n\n    time_elapsed = time.time() - since\n    print('Training complete in {:.0f}m {:.0f}s'.format(\n        time_elapsed // 60, time_elapsed % 60))\n    print('Best val Acc: {:4f}'.format(best_acc))\n\n    # load best model weights\n    model.load_state_dict(best_model_wts)\n    return model","metadata":{"execution":{"iopub.status.busy":"2024-07-16T07:51:47.628848Z","iopub.execute_input":"2024-07-16T07:51:47.629174Z","iopub.status.idle":"2024-07-16T07:51:47.642128Z","shell.execute_reply.started":"2024-07-16T07:51:47.629141Z","shell.execute_reply":"2024-07-16T07:51:47.641171Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"data_dir = '/kaggle/input/classify-by-brand-dataset-fixed/classify_by_brand/classify_by_brand_dataset'\n\nmodel = models.resnet18(pretrained = True)\n# for param in model.parameters():\n#     param.requires_grad = False\nnum_ftrs = model.fc.in_features\nmodel.fc = nn.Linear(num_ftrs, 1)\nmodel = nn.Sequential(model, nn.Sigmoid())\nmodel.to(device)","metadata":{"execution":{"iopub.status.busy":"2024-07-16T07:51:47.644670Z","iopub.execute_input":"2024-07-16T07:51:47.645036Z","iopub.status.idle":"2024-07-16T07:51:48.621420Z","shell.execute_reply.started":"2024-07-16T07:51:47.645003Z","shell.execute_reply":"2024-07-16T07:51:48.620319Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n  warnings.warn(msg)\nDownloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n100%|██████████| 44.7M/44.7M [00:00<00:00, 133MB/s] \n","output_type":"stream"},{"execution_count":15,"output_type":"execute_result","data":{"text/plain":"Sequential(\n  (0): ResNet(\n    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (relu): ReLU(inplace=True)\n    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n    (layer1): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (layer2): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (layer3): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (layer4): Sequential(\n      (0): BasicBlock(\n        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (downsample): Sequential(\n          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        )\n      )\n      (1): BasicBlock(\n        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n        (relu): ReLU(inplace=True)\n        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n      )\n    )\n    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n    (fc): Linear(in_features=512, out_features=1, bias=True)\n  )\n  (1): Sigmoid()\n)"},"metadata":{}}]},{"cell_type":"code","source":"criterion = nn.BCELoss()\nopt = torch.optim.Adam(model[0].fc.parameters(), lr=0.001)\nmodel = train_model(model, criterion, opt,\n                         num_epochs=15)","metadata":{"execution":{"iopub.status.busy":"2024-07-16T08:06:26.942089Z","iopub.execute_input":"2024-07-16T08:06:26.942600Z","iopub.status.idle":"2024-07-16T08:38:13.001068Z","shell.execute_reply.started":"2024-07-16T08:06:26.942566Z","shell.execute_reply":"2024-07-16T08:38:12.999993Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Epoch 0/14\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 60/60 [01:07<00:00,  1.13s/it]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.1872 Acc: 0.9308\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7778/7778 [00:58<00:00, 132.45it/s]\n","output_type":"stream"},{"name":"stdout","text":"cv Loss: 0.4292 Acc: 0.8237\n\nEpoch 1/14\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 60/60 [01:09<00:00,  1.16s/it]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.1828 Acc: 0.9357\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7778/7778 [01:06<00:00, 116.56it/s]\n","output_type":"stream"},{"name":"stdout","text":"cv Loss: 0.4301 Acc: 0.8266\n\nEpoch 2/14\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 60/60 [01:10<00:00,  1.18s/it]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.1782 Acc: 0.9359\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7778/7778 [01:03<00:00, 121.58it/s]\n","output_type":"stream"},{"name":"stdout","text":"cv Loss: 0.4328 Acc: 0.8268\n\nEpoch 3/14\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 60/60 [01:09<00:00,  1.16s/it]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.1790 Acc: 0.9376\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7778/7778 [01:04<00:00, 119.74it/s]\n","output_type":"stream"},{"name":"stdout","text":"cv Loss: 0.4306 Acc: 0.8239\n\nEpoch 4/14\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 60/60 [01:09<00:00,  1.16s/it]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.1800 Acc: 0.9372\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7778/7778 [00:58<00:00, 132.42it/s]\n","output_type":"stream"},{"name":"stdout","text":"cv Loss: 0.4304 Acc: 0.8233\n\nEpoch 5/14\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 60/60 [01:09<00:00,  1.16s/it]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.1789 Acc: 0.9353\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7778/7778 [00:57<00:00, 134.27it/s]\n","output_type":"stream"},{"name":"stdout","text":"cv Loss: 0.4313 Acc: 0.8303\n\nEpoch 6/14\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 60/60 [01:06<00:00,  1.11s/it]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.1761 Acc: 0.9366\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7778/7778 [00:55<00:00, 140.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"cv Loss: 0.4345 Acc: 0.8293\n\nEpoch 7/14\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 60/60 [01:05<00:00,  1.09s/it]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.1763 Acc: 0.9380\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7778/7778 [00:56<00:00, 137.73it/s]\n","output_type":"stream"},{"name":"stdout","text":"cv Loss: 0.4302 Acc: 0.8273\n\nEpoch 8/14\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 60/60 [01:06<00:00,  1.11s/it]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.1737 Acc: 0.9380\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7778/7778 [00:55<00:00, 140.24it/s]\n","output_type":"stream"},{"name":"stdout","text":"cv Loss: 0.4322 Acc: 0.8159\n\nEpoch 9/14\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 60/60 [01:06<00:00,  1.11s/it]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.1755 Acc: 0.9383\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7778/7778 [00:56<00:00, 137.52it/s]\n","output_type":"stream"},{"name":"stdout","text":"cv Loss: 0.4444 Acc: 0.8349\n\nEpoch 10/14\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 60/60 [01:08<00:00,  1.14s/it]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.1737 Acc: 0.9374\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7778/7778 [00:59<00:00, 130.03it/s]\n","output_type":"stream"},{"name":"stdout","text":"cv Loss: 0.4283 Acc: 0.8269\n\nEpoch 11/14\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 60/60 [01:08<00:00,  1.13s/it]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.1705 Acc: 0.9398\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7778/7778 [00:58<00:00, 134.06it/s]\n","output_type":"stream"},{"name":"stdout","text":"cv Loss: 0.4403 Acc: 0.8353\n\nEpoch 12/14\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 60/60 [01:07<00:00,  1.13s/it]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.1690 Acc: 0.9392\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7778/7778 [00:57<00:00, 134.36it/s]\n","output_type":"stream"},{"name":"stdout","text":"cv Loss: 0.4307 Acc: 0.8271\n\nEpoch 13/14\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 60/60 [01:08<00:00,  1.14s/it]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.1719 Acc: 0.9394\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7778/7778 [00:57<00:00, 135.79it/s]\n","output_type":"stream"},{"name":"stdout","text":"cv Loss: 0.4398 Acc: 0.8322\n\nEpoch 14/14\n----------\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 60/60 [01:06<00:00,  1.11s/it]\n","output_type":"stream"},{"name":"stdout","text":"train Loss: 0.1737 Acc: 0.9379\n","output_type":"stream"},{"name":"stderr","text":"100%|██████████| 7778/7778 [00:56<00:00, 136.82it/s]","output_type":"stream"},{"name":"stdout","text":"cv Loss: 0.4513 Acc: 0.8349\n\nTraining complete in 31m 46s\nBest val Acc: 0.000000\n","output_type":"stream"},{"name":"stderr","text":"\n","output_type":"stream"}]},{"cell_type":"code","source":"torch.save(model, '/kaggle/working/best.pt')","metadata":{"execution":{"iopub.status.busy":"2024-07-16T08:52:53.780134Z","iopub.execute_input":"2024-07-16T08:52:53.780555Z","iopub.status.idle":"2024-07-16T08:52:53.873560Z","shell.execute_reply.started":"2024-07-16T08:52:53.780523Z","shell.execute_reply":"2024-07-16T08:52:53.872529Z"},"trusted":true},"execution_count":21,"outputs":[]}]}